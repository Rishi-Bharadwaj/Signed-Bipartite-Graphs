{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(file_path):\n",
    "    edgelist = []\n",
    "    set_a = []\n",
    "    set_b = []\n",
    "\n",
    "    with open(file_path) as f:\n",
    "        for ind, line in enumerate(f):\n",
    "            if ind == 0: \n",
    "                na, nb, ns = map(int, line.split('\\t'))\n",
    "                set_b = [f\"set_b_{i}\" for i in range(nb)]\n",
    "                set_a = [f\"set_a_{i}\" for i in range(na)]\n",
    "                continue\n",
    "            a, b, s = map(int, line.split('\\t'))\n",
    "            if s == 1:\n",
    "                edgelist.append((f\"set_a_{a}\", f\"set_b_{b}\", {'sign': '+1'}))\n",
    "            else:\n",
    "                edgelist.append((f\"set_a_{a}\", f\"set_b_{b}\", {'sign': '-1'}))\n",
    "\n",
    "    B = nx.Graph()\n",
    "    B.add_nodes_from(set_a, bipartite=0)\n",
    "    B.add_nodes_from(set_b, bipartite=1)\n",
    "    B.add_edges_from(edgelist)\n",
    "    \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_drawing(B, set_a, set_b):\n",
    "\n",
    "    colors = ['yellow' for _ in set_a] + ['green' for _ in set_b]\n",
    "    \n",
    " \n",
    "    num_nodes = B.number_of_nodes()\n",
    "    print(\"Number of nodes in the graph:\", num_nodes)\n",
    "    \n",
    "\n",
    "    edge_colors = []\n",
    "    for u, v, attrs in B.edges(data=True):\n",
    "        if attrs['sign'] == '+1':\n",
    "            edge_colors.append('blue')   \n",
    "        else:\n",
    "            edge_colors.append('red')   \n",
    "    \n",
    "\n",
    "    nx.draw(B, with_labels=False, node_color=colors, edge_color=edge_colors)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_prob=0.4):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, output_dim)   \n",
    "        self.dropout = nn.Dropout(p=dropout_prob)   \n",
    "        self.output_layer = nn.Linear(output_dim, output_dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))    \n",
    "        x = self.dropout(x)       \n",
    "        x = self.output_layer(x)   \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SBGNN(nn.Module):\n",
    "    def __init__(self, graph, emb_dim_a=32, emb_dim_b=32):\n",
    "        super(SBGNN, self).__init__()\n",
    "\n",
    "        self.graph = graph\n",
    "        self.set_a = [n for n, d in self.graph.nodes(data=True) if d['bipartite'] == 0]\n",
    "        self.set_b = [n for n, d in self.graph.nodes(data=True) if d['bipartite'] == 1]\n",
    "        self.emb_dim_a = emb_dim_a\n",
    "        self.emb_dim_b = emb_dim_b\n",
    "\n",
    "        # Initialize ParameterDict for features_a and features_b\n",
    "        self.features_a = nn.ParameterDict({str(node): nn.Parameter(torch.randn(1, self.emb_dim_a)) for node in self.set_a})\n",
    "        self.features_b = nn.ParameterDict({str(node): nn.Parameter(torch.randn(1, self.emb_dim_b)) for node in self.set_b})\n",
    "\n",
    "        self.weight_a_b = nn.Parameter(torch.randn(self.emb_dim_a, self.emb_dim_a))\n",
    "        self.weight_a_u = nn.Parameter(torch.randn(self.emb_dim_a, self.emb_dim_a))\n",
    "        self.weight_b_b = nn.Parameter(torch.randn(self.emb_dim_b, self.emb_dim_b))\n",
    "        self.weight_b_u = nn.Parameter(torch.randn(self.emb_dim_b, self.emb_dim_b))\n",
    "\n",
    "        self.mlp_a = MLP(3 * self.emb_dim_a, self.emb_dim_a)\n",
    "        self.mlp_b = MLP(3 * self.emb_dim_b, self.emb_dim_b)\n",
    "\n",
    "    def message_passing(self, iterations=1):\n",
    "        for i in range(iterations):\n",
    "            new_features_a = {}\n",
    "            new_features_b = {}\n",
    "\n",
    "            for node in self.set_a:\n",
    "                new_features_a_b = torch.zeros(self.emb_dim_a, device=self.features_a[str(node)].device)\n",
    "                new_features_a_u = torch.zeros(self.emb_dim_a, device=self.features_a[str(node)].device)\n",
    "                count_b = 0\n",
    "                count_u = 0\n",
    "\n",
    "                for neighbor in self.graph.neighbors(node):\n",
    "                    sign = self.graph.edges[node, neighbor]['sign']\n",
    "                    if sign == '+1':\n",
    "                        new_features_a_b += self.features_b[str(neighbor)].squeeze(0)\n",
    "                        count_b += 1\n",
    "                    else:\n",
    "                        new_features_a_u += self.features_b[str(neighbor)].squeeze(0)\n",
    "                        count_u += 1\n",
    "\n",
    "                if count_b > 0:\n",
    "                    new_features_a_b /= count_b\n",
    "                    new_features_a_b = torch.matmul(new_features_a_b, self.weight_a_b)\n",
    "\n",
    "                if count_u > 0:\n",
    "                    new_features_a_u /= count_u\n",
    "                    new_features_a_u = torch.matmul(new_features_a_u, self.weight_a_u)\n",
    "\n",
    "                new_features_a[str(node)] = torch.cat((new_features_a_b, new_features_a_u, self.features_a[str(node)].squeeze(0)), dim=0)\n",
    "                new_features_a[str(node)] = self.mlp_a(new_features_a[str(node)])\n",
    "                new_features_a[str(node)] = nn.Parameter(new_features_a[str(node)])\n",
    "\n",
    "            for node in self.set_b:\n",
    "                new_features_b_b = torch.zeros(self.emb_dim_b, device=self.features_b[str(node)].device)\n",
    "                new_features_b_u = torch.zeros(self.emb_dim_b, device=self.features_b[str(node)].device)\n",
    "                count_b = 0\n",
    "                count_u = 0\n",
    "\n",
    "                for neighbor in self.graph.neighbors(node):\n",
    "                    sign = self.graph.edges[node, neighbor]['sign']\n",
    "                    if sign == '+1':\n",
    "                        new_features_b_b += self.features_a[str(neighbor)].squeeze(0)\n",
    "                        count_b += 1\n",
    "                    else:\n",
    "                        new_features_b_u += self.features_a[str(neighbor)].squeeze(0)\n",
    "                        count_u += 1\n",
    "\n",
    "                if count_b > 0:\n",
    "                    new_features_b_b /= count_b\n",
    "                    new_features_b_b = torch.matmul(new_features_b_b, self.weight_b_b)\n",
    "\n",
    "                if count_u > 0:\n",
    "                    new_features_b_u /= count_u\n",
    "                    new_features_b_u = torch.matmul(new_features_b_u, self.weight_b_u)\n",
    "\n",
    "                new_features_b[str(node)] = torch.cat((new_features_b_b, new_features_b_u, self.features_b[str(node)].squeeze(0)), dim=0)\n",
    "                new_features_b[str(node)] = self.mlp_b(new_features_b[str(node)])\n",
    "                new_features_b[str(node)] = nn.Parameter(new_features_b[str(node)])\n",
    "\n",
    "            # Update ParameterDicts\n",
    "            for node in self.set_a:\n",
    "                self.features_a[str(node)] = new_features_a[str(node)].unsqueeze(0)\n",
    "\n",
    "            for node in self.set_b:\n",
    "                self.features_b[str(node)] = new_features_b[str(node)].unsqueeze(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax(nn.Module):\n",
    "    def __init__(self, input_dim, cluster_number):\n",
    "        super(Softmax, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, cluster_number)  # Fully connected layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)         # Apply the fully connected layer\n",
    "        x = F.softmax(x, dim=0)  # Apply softmax to the output\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Community(nn.Module):\n",
    "    def __init__(self, sbgnn, cluster_number):\n",
    "        super(Community, self).__init__()\n",
    "        \n",
    "        self.sbgnn=sbgnn\n",
    "        self.cluster_number=cluster_number\n",
    "        self.emb_dim_a=self.sbgnn.emb_dim_a\n",
    "        self.emb_dim_b=self.sbgnn.emb_dim_b\n",
    "\n",
    "        self.Softmax_a=Softmax(self.emb_dim_a,self.cluster_number)\n",
    "        self.Softmax_b=Softmax(self.emb_dim_b,self.cluster_number)\n",
    "\n",
    "\n",
    "    def build_communities(self):\n",
    "        self.list_a=[]\n",
    "        self.list_b=[]\n",
    "        \n",
    "        for node in self.sbgnn.set_a:\n",
    "            new_tensor=self.sbgnn.features_a[str(node)].squeeze(0)\n",
    "            new_tensor=self.Softmax_a(new_tensor)\n",
    "            self.list_a.append(new_tensor)\n",
    "        \n",
    "        self.C_a=torch.stack(self.list_a,dim=0).squeeze(0)\n",
    "        self.C_a=self.C_a.to(dtype=torch.float64)\n",
    "\n",
    "\n",
    "        for node in self.sbgnn.set_b:\n",
    "            new_tensor=self.sbgnn.features_b[str(node)].squeeze(0)\n",
    "            new_tensor=self.Softmax_b(new_tensor)\n",
    "            self.list_b.append(new_tensor)\n",
    "        \n",
    "        self.C_b=torch.stack(self.list_b,dim=0).squeeze(0)\n",
    "        self.C_b=self.C_b.to(dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modularity(nn.Module):\n",
    "    def __init__(self,sbgnn,community):\n",
    "        super(Modularity, self).__init__()\n",
    "\n",
    "        self.graph=sbgnn.graph\n",
    "        self.set_a = sbgnn.set_a\n",
    "        self.set_b = sbgnn.set_b\n",
    "        self.n=len(self.set_a)\n",
    "        self.m=len(self.set_b)\n",
    "\n",
    "        self.community=community\n",
    "        self.C_a=self.community.C_a\n",
    "        self.C_b=self.community.C_b\n",
    "        self.k=self.community.cluster_number\n",
    "\n",
    "        self.positive_counts={node:0 for node in self.graph.nodes()}\n",
    "        self.negative_counts={node:0 for node in self.graph.nodes()}\n",
    "        self.total_positive=0\n",
    "        self.total_negative=0\n",
    "\n",
    "\n",
    "    def build_adjacency_matrix(self):\n",
    "        matrix = np.zeros((self.n, self.m))\n",
    "        for i, a_node in enumerate(self.set_a):\n",
    "            for j, b_node in enumerate(self.set_b):\n",
    "                if self.graph.has_edge(a_node, b_node) and self.graph[a_node][b_node]['sign']=='+1':\n",
    "                    matrix[i, j] = 1\n",
    "                elif self.graph.has_edge(a_node, b_node) and self.graph[a_node][b_node]['sign']=='-1':\n",
    "                    matrix[i,j] = -1\n",
    "        self.adj_matrix=torch.from_numpy(matrix).to(device)\n",
    "\n",
    "\n",
    "    def count_edges(self):\n",
    "        for u, v, data in self.graph.edges(data=True):\n",
    "            if data['sign'] =='+1':\n",
    "                self.positive_counts[u] += 1\n",
    "                self.positive_counts[v] += 1\n",
    "                self.total_positive+=1\n",
    "            elif data['sign'] =='-1':\n",
    "                self.negative_counts[u] += 1\n",
    "                self.negative_counts[v] += 1\n",
    "                self.total_negative+=1\n",
    "        \n",
    "        self.positive_plus_negative=self.total_positive+self.total_negative\n",
    "    \n",
    "    def build_W_matrix(self):\n",
    "        matrix=[]\n",
    "        for node_i in self.set_a:\n",
    "            temp_list=[]\n",
    "            for node_j in self.set_b:\n",
    "                pos=(self.positive_counts[node_i]*self.positive_counts[node_j])/self.total_positive\n",
    "                neg=(self.negative_counts[node_i]*self.negative_counts[node_j])/self.total_negative\n",
    "                temp_list.append(pos-neg)\n",
    "            matrix.append(temp_list)\n",
    "        matrix=np.matrix(matrix)\n",
    "        matrix = self.adj_matrix.cpu().numpy() - matrix\n",
    "        self.W_matrix=torch.from_numpy(matrix).to(device)\n",
    "\n",
    "    def find_modularity(self):\n",
    "        denominator=1/self.positive_plus_negative\n",
    "        final_matrix= torch.matmul(self.C_a.t(),self.W_matrix)\n",
    "        self.final_matrix=torch.matmul(final_matrix,self.C_b)\n",
    "        self.trace=torch.trace(self.final_matrix)\n",
    "        self.modularity=denominator*self.trace\n",
    "\n",
    "\n",
    "    def loss_function(self):\n",
    "\n",
    "        self.soft_count_a=torch.sum(self.C_a,dim=0)\n",
    "        self.soft_count_b=torch.sum(self.C_b,dim=0)\n",
    "\n",
    "        self.frobenius_norm_a=torch.norm(self.soft_count_a,p='fro')\n",
    "        self.frobenius_norm_b=torch.norm(self.soft_count_b,p='fro')\n",
    "\n",
    "        self.reg_a=(np.sqrt(self.k)/self.n)*self.frobenius_norm_a\n",
    "        self.reg_b=(np.sqrt(self.k)/self.m)*self.frobenius_norm_b\n",
    "\n",
    "        self.regularization=self.reg_a+self.reg_b -2\n",
    "\n",
    "        self.loss= self.regularization-self.modularity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sbgnn(sbgnn, community, lr=0.01, epochs=10):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    sbgnn.to(device)\n",
    "    community.to(device)\n",
    "    all_params = set(sbgnn.parameters()) | set(community.parameters())\n",
    "    \n",
    "    # Create optimizer\n",
    "    optimizer = optim.Adam(all_params, lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        sbgnn.message_passing(iterations=2)\n",
    "        community.build_communities()\n",
    "        modularity=Modularity(sbgnn,community)\n",
    "        modularity.to(device)\n",
    "        modularity.build_adjacency_matrix()\n",
    "        modularity.count_edges()\n",
    "        modularity.build_W_matrix()\n",
    "        modularity.find_modularity()\n",
    "        modularity.loss_function()\n",
    "\n",
    "        loss = modularity.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 1 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "            print(f\"Modularity : {modularity.modularity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\rishi\\ml_projects\\SBGNN\\synthetic.txt\"\n",
    "B = load_graph(file_path)\n",
    "# set_a = [n for n, d in B.nodes(data=True) if d['bipartite'] == 0]\n",
    "# set_b = [n for n, d in B.nodes(data=True) if d['bipartite'] == 1]\n",
    "#build_drawing(B,set_a,set_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.05402932982476787\n",
      "Modularity : -0.00011420448944182076\n",
      "Epoch 1, Loss: 0.12641038495670334\n",
      "Modularity : -0.00018308099949896587\n",
      "Epoch 2, Loss: 0.10851968377287265\n",
      "Modularity : -0.00017587949106919295\n",
      "Epoch 3, Loss: 0.08468681937576233\n",
      "Modularity : -0.0005836735962389577\n",
      "Epoch 4, Loss: 0.10670169760884225\n",
      "Modularity : -4.9045067808182675e-05\n",
      "Epoch 5, Loss: 0.1120054170143294\n",
      "Modularity : -0.0019091434834163908\n",
      "Epoch 6, Loss: 0.21657913506619794\n",
      "Modularity : 0.00040192390739749926\n",
      "Epoch 7, Loss: 0.33520884241819016\n",
      "Modularity : -0.005883272107641736\n",
      "Epoch 8, Loss: 0.7187090745652465\n",
      "Modularity : 0.001067072126609947\n",
      "Epoch 9, Loss: 1.0637092514459539\n",
      "Modularity : -0.017282760451075914\n"
     ]
    }
   ],
   "source": [
    "sbgnn=SBGNN(B,32,32)\n",
    "community=Community(sbgnn,2)\n",
    "\n",
    "train_sbgnn(sbgnn,community)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
