{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(file_path):\n",
    "    edgelist = []\n",
    "    set_a = []\n",
    "    set_b = []\n",
    "\n",
    "    with open(file_path) as f:\n",
    "        for ind, line in enumerate(f):\n",
    "            if ind == 0: \n",
    "                na, nb, ns = map(int, line.split('\\t'))\n",
    "                set_b = [f\"set_b_{i}\" for i in range(nb)]\n",
    "                set_a = [f\"set_a_{i}\" for i in range(na)]\n",
    "                continue\n",
    "            a, b, s = map(int, line.split('\\t'))\n",
    "            if s == 1:\n",
    "                edgelist.append((f\"set_a_{a}\", f\"set_b_{b}\", {'sign': '+1'}))\n",
    "            else:\n",
    "                edgelist.append((f\"set_a_{a}\", f\"set_b_{b}\", {'sign': '-1'}))\n",
    "\n",
    "    B = nx.Graph()\n",
    "    B.add_nodes_from(set_a, bipartite=0)\n",
    "    B.add_nodes_from(set_b, bipartite=1)\n",
    "    B.add_edges_from(edgelist)\n",
    "    \n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_drawing(B, set_a, set_b):\n",
    "\n",
    "    colors = ['yellow' for _ in set_a] + ['green' for _ in set_b]\n",
    "    \n",
    " \n",
    "    num_nodes = B.number_of_nodes()\n",
    "    print(\"Number of nodes in the graph:\", num_nodes)\n",
    "    \n",
    "\n",
    "    edge_colors = []\n",
    "    for u, v, attrs in B.edges(data=True):\n",
    "        if attrs['sign'] == '+1':\n",
    "            edge_colors.append('blue')   \n",
    "        else:\n",
    "            edge_colors.append('red')   \n",
    "    \n",
    "\n",
    "    nx.draw(B, with_labels=False, node_color=colors, edge_color=edge_colors)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout_prob=0.4):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, output_dim)   \n",
    "        self.dropout = nn.Dropout(p=dropout_prob)   \n",
    "        self.output_layer = nn.Linear(output_dim, output_dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))    \n",
    "        x = self.dropout(x)       \n",
    "        x = self.output_layer(x)   \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SBGNN(nn.Module):\n",
    "    def __init__(self, graph, emb_dim_a=32, emb_dim_b=32):\n",
    "        super(SBGNN, self).__init__()\n",
    "\n",
    "        self.graph = graph\n",
    "        self.set_a = [n for n, d in self.graph.nodes(data=True) if d['bipartite'] == 0]\n",
    "        self.set_b = [n for n, d in self.graph.nodes(data=True) if d['bipartite'] == 1]\n",
    "        self.emb_dim_a = emb_dim_a\n",
    "        self.emb_dim_b = emb_dim_b\n",
    "\n",
    "        # Initialize ModuleDict for features_a and features_b\n",
    "        self.features_a = nn.ModuleDict({str(node): nn.Embedding(1, self.emb_dim_a) for node in self.set_a})\n",
    "        self.features_b = nn.ModuleDict({str(node): nn.Embedding(1, self.emb_dim_b) for node in self.set_b})\n",
    "\n",
    "        self.weight_a_b = nn.Parameter(torch.randn(self.emb_dim_a, self.emb_dim_a))\n",
    "        self.weight_a_u = nn.Parameter(torch.randn(self.emb_dim_a, self.emb_dim_a))\n",
    "        self.weight_b_b = nn.Parameter(torch.randn(self.emb_dim_b, self.emb_dim_b))\n",
    "        self.weight_b_u = nn.Parameter(torch.randn(self.emb_dim_b, self.emb_dim_b))\n",
    "\n",
    "        self.mlp_a = MLP(3 * self.emb_dim_a, self.emb_dim_a)\n",
    "        self.mlp_b = MLP(3 * self.emb_dim_b, self.emb_dim_b)\n",
    "\n",
    "    def message_passing(self, iterations=1):\n",
    "        for i in range(iterations):\n",
    "            new_features_a = {}\n",
    "            new_features_b = {}\n",
    "\n",
    "            for node in self.set_a:\n",
    "                new_features_a_b = torch.zeros(self.emb_dim_a,device=device)\n",
    "                new_features_a_u = torch.zeros(self.emb_dim_a,device=device)\n",
    "                count_b = 0\n",
    "                count_u = 0\n",
    "\n",
    "                for neighbor in self.graph.neighbors(node):\n",
    "                        sign = self.graph.edges[node, neighbor]['sign']\n",
    "                        if sign == '+1':\n",
    "                            new_features_a_b += self.features_b[str(neighbor)].weight.squeeze(0)\n",
    "                            count_b += 1\n",
    "                        else:\n",
    "                            new_features_a_u += self.features_b[str(neighbor)].weight.squeeze(0)\n",
    "                            count_u += 1\n",
    "\n",
    "                if count_b > 0:\n",
    "                    new_features_a_b /= count_b\n",
    "                    new_features_a_b = torch.matmul(new_features_a_b, self.weight_a_b)\n",
    "\n",
    "                if count_u > 0:\n",
    "                    new_features_a_u /= count_u\n",
    "                    new_features_a_u = torch.matmul(new_features_a_u, self.weight_a_u)\n",
    "\n",
    "                new_features_a[str(node)] = torch.cat((new_features_a_b, new_features_a_u, self.features_a[str(node)].weight.squeeze(0)), dim=0)\n",
    "                new_features_a[str(node)] = self.mlp_a(new_features_a[str(node)])\n",
    "\n",
    "            for node in self.set_b:\n",
    "                new_features_b_b = torch.zeros(self.emb_dim_b,device=device)\n",
    "                new_features_b_u = torch.zeros(self.emb_dim_b,device=device)\n",
    "                count_b = 0\n",
    "                count_u = 0\n",
    "\n",
    "                for neighbor in self.graph.neighbors(node):\n",
    "                        sign = self.graph.edges[node, neighbor]['sign']\n",
    "                        if sign == '+1':\n",
    "                            new_features_b_b += self.features_a[str(neighbor)].weight.squeeze(0)\n",
    "                            count_b += 1\n",
    "                        else:\n",
    "                            new_features_b_u += self.features_a[str(neighbor)].weight.squeeze(0)\n",
    "                            count_u += 1\n",
    "\n",
    "                if count_b > 0:\n",
    "                    new_features_b_b /= count_b\n",
    "                    new_features_b_b = torch.matmul(new_features_b_b, self.weight_b_b)\n",
    "\n",
    "                if count_u > 0:\n",
    "                    new_features_b_u /= count_u\n",
    "                    new_features_b_u = torch.matmul(new_features_b_u, self.weight_b_u)\n",
    "\n",
    "                new_features_b[str(node)] = torch.cat((new_features_b_b, new_features_b_u, self.features_b[str(node)].weight.squeeze(0)), dim=0)\n",
    "                new_features_b[str(node)] = self.mlp_b(new_features_b[str(node)])\n",
    "\n",
    "            # Update ModuleDicts\n",
    "            for node in self.set_a:\n",
    "                self.features_a[str(node)].weight = nn.Parameter(new_features_a[str(node)].unsqueeze(0))\n",
    "\n",
    "            for node in self.set_b:\n",
    "                self.features_b[str(node)].weight = nn.Parameter(new_features_b[str(node)].unsqueeze(0))\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax(nn.Module):\n",
    "    def __init__(self, input_dim, cluster_number):\n",
    "        super(Softmax, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, cluster_number)  # Fully connected layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)         # Apply the fully connected layer\n",
    "        x = F.softmax(x, dim=0)  # Apply softmax to the output\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Community(nn.Module):\n",
    "    def __init__(self, sbgnn, cluster_number):\n",
    "        super(Community, self).__init__()\n",
    "        \n",
    "        self.sbgnn=sbgnn\n",
    "        self.cluster_number=cluster_number\n",
    "        self.emb_dim_a=self.sbgnn.emb_dim_a\n",
    "        self.emb_dim_b=self.sbgnn.emb_dim_b\n",
    "\n",
    "        self.Softmax_a=Softmax(self.emb_dim_a,self.cluster_number)\n",
    "        self.Softmax_b=Softmax(self.emb_dim_b,self.cluster_number)\n",
    "\n",
    "\n",
    "    def build_communities(self):\n",
    "        self.list_a=[]\n",
    "        self.list_b=[]\n",
    "        \n",
    "        for node in self.sbgnn.set_a:\n",
    "            new_tensor=self.sbgnn.features_a[str(node)].weight.squeeze(0)\n",
    "            new_tensor=self.Softmax_a(new_tensor)\n",
    "            self.list_a.append(new_tensor)\n",
    "        \n",
    "        self.C_a=torch.stack(self.list_a,dim=0).squeeze(0)\n",
    "        self.C_a=self.C_a.to(dtype=torch.float64)\n",
    "\n",
    "\n",
    "        for node in self.sbgnn.set_b:\n",
    "            new_tensor=self.sbgnn.features_b[str(node)].weight.squeeze(0)\n",
    "            new_tensor=self.Softmax_b(new_tensor)\n",
    "            self.list_b.append(new_tensor)\n",
    "        \n",
    "        self.C_b=torch.stack(self.list_b,dim=0).squeeze(0)\n",
    "        self.C_b=self.C_b.to(dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modularity(nn.Module):\n",
    "    def __init__(self,sbgnn,community):\n",
    "        super(Modularity, self).__init__()\n",
    "\n",
    "        self.graph=sbgnn.graph\n",
    "        self.set_a = sbgnn.set_a\n",
    "        self.set_b = sbgnn.set_b\n",
    "        self.n=len(self.set_a)\n",
    "        self.m=len(self.set_b)\n",
    "\n",
    "        self.community=community\n",
    "        self.C_a=self.community.C_a\n",
    "        self.C_b=self.community.C_b\n",
    "        self.k=self.community.cluster_number\n",
    "\n",
    "        self.positive_counts={node:0 for node in self.graph.nodes()}\n",
    "        self.negative_counts={node:0 for node in self.graph.nodes()}\n",
    "        self.total_positive=0\n",
    "        self.total_negative=0\n",
    "\n",
    "\n",
    "    def build_adjacency_matrix(self):\n",
    "        matrix = np.zeros((self.n, self.m))\n",
    "        for i, a_node in enumerate(self.set_a):\n",
    "            for j, b_node in enumerate(self.set_b):\n",
    "                if self.graph.has_edge(a_node, b_node) and self.graph[a_node][b_node]['sign']=='+1':\n",
    "                    matrix[i, j] = 1\n",
    "                elif self.graph.has_edge(a_node, b_node) and self.graph[a_node][b_node]['sign']=='-1':\n",
    "                    matrix[i,j] = -1\n",
    "        self.adj_matrix=torch.from_numpy(matrix).to(device)\n",
    "\n",
    "\n",
    "    def count_edges(self):\n",
    "        for u, v, data in self.graph.edges(data=True):\n",
    "            if data['sign'] =='+1':\n",
    "                self.positive_counts[u] += 1\n",
    "                self.positive_counts[v] += 1\n",
    "                self.total_positive+=1\n",
    "            elif data['sign'] =='-1':\n",
    "                self.negative_counts[u] += 1\n",
    "                self.negative_counts[v] += 1\n",
    "                self.total_negative+=1\n",
    "        \n",
    "        self.positive_plus_negative=self.total_positive+self.total_negative\n",
    "    \n",
    "    def build_W_matrix(self):\n",
    "        matrix=[]\n",
    "        for node_i in self.set_a:\n",
    "            temp_list=[]\n",
    "            for node_j in self.set_b:\n",
    "                pos=(self.positive_counts[node_i]*self.positive_counts[node_j])/self.total_positive\n",
    "                neg=(self.negative_counts[node_i]*self.negative_counts[node_j])/self.total_negative\n",
    "                temp_list.append(pos-neg)\n",
    "            matrix.append(temp_list)\n",
    "        matrix=np.matrix(matrix)\n",
    "        matrix = self.adj_matrix.cpu().numpy() - matrix\n",
    "        self.W_matrix=torch.from_numpy(matrix).to(device)\n",
    "\n",
    "    def find_modularity(self):\n",
    "        denominator=1/self.positive_plus_negative\n",
    "        final_matrix= torch.matmul(self.C_a.t(),self.W_matrix)\n",
    "        self.final_matrix=torch.matmul(final_matrix,self.C_b)\n",
    "        self.trace=torch.trace(self.final_matrix)\n",
    "        self.modularity=denominator*self.trace\n",
    "\n",
    "\n",
    "    def loss_function(self):\n",
    "\n",
    "        self.soft_count_a=torch.sum(self.C_a,dim=0)\n",
    "        self.soft_count_b=torch.sum(self.C_b,dim=0)\n",
    "\n",
    "        self.frobenius_norm_a=torch.norm(self.soft_count_a,p='fro')\n",
    "        self.frobenius_norm_b=torch.norm(self.soft_count_b,p='fro')\n",
    "\n",
    "        self.reg_a=(np.sqrt(self.k)/self.n)*self.frobenius_norm_a\n",
    "        self.reg_b=(np.sqrt(self.k)/self.m)*self.frobenius_norm_b\n",
    "\n",
    "        self.regularization=self.reg_a+self.reg_b -2\n",
    "\n",
    "        self.loss= self.regularization-self.modularity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sbgnn(sbgnn, community, lr=0.01, epochs=10):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    sbgnn.to(device)\n",
    "    community.to(device)\n",
    "    optimizer = optim.Adam(list(sbgnn.parameters()) + list(community.parameters()), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        sbgnn.message_passing(iterations=2)\n",
    "        community.build_communities()\n",
    "        modularity=Modularity(sbgnn,community)\n",
    "        modularity.to(device)\n",
    "        modularity.build_adjacency_matrix()\n",
    "        modularity.count_edges()\n",
    "        modularity.build_W_matrix()\n",
    "        modularity.find_modularity()\n",
    "        modularity.loss_function()\n",
    "\n",
    "        loss = modularity.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 1 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "            print(f\"Modularity : {modularity.modularity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"C:\\Users\\rishi\\ml_projects\\SBGNN\\senate1to10.txt\"\n",
    "B = load_graph(file_path)\n",
    "# set_a = [n for n, d in B.nodes(data=True) if d['bipartite'] == 0]\n",
    "# set_b = [n for n, d in B.nodes(data=True) if d['bipartite'] == 1]\n",
    "#build_drawing(B,set_a,set_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.03427046178521733\n",
      "Modularity : 9.130466987828017e-07\n",
      "Epoch 1, Loss: 0.02431806987839236\n",
      "Modularity : 5.683600129394359e-07\n",
      "Epoch 2, Loss: 0.026534582011598366\n",
      "Modularity : 2.2398995617692435e-06\n",
      "Epoch 3, Loss: 0.026242184289507683\n",
      "Modularity : -5.473046525915146e-06\n",
      "Epoch 4, Loss: 0.04293806321631391\n",
      "Modularity : -2.3369250226082926e-05\n",
      "Epoch 5, Loss: 0.052336137959806704\n",
      "Modularity : -1.0075599805668753e-05\n",
      "Epoch 6, Loss: 0.045062276171896336\n",
      "Modularity : -8.197687740787586e-06\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[124], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m sbgnn\u001b[38;5;241m=\u001b[39mSBGNN(B,\u001b[38;5;241m32\u001b[39m,\u001b[38;5;241m32\u001b[39m)\n\u001b[0;32m      2\u001b[0m community\u001b[38;5;241m=\u001b[39mCommunity(sbgnn,\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m train_sbgnn(sbgnn,community)\n",
      "Cell \u001b[1;32mIn[122], line 9\u001b[0m, in \u001b[0;36mtrain_sbgnn\u001b[1;34m(sbgnn, community, lr, epochs)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m      8\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m----> 9\u001b[0m     sbgnn\u001b[38;5;241m.\u001b[39mmessage_passing(iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     10\u001b[0m     community\u001b[38;5;241m.\u001b[39mbuild_communities()\n\u001b[0;32m     11\u001b[0m     modularity\u001b[38;5;241m=\u001b[39mModularity(sbgnn,community)\n",
      "Cell \u001b[1;32mIn[69], line 38\u001b[0m, in \u001b[0;36mSBGNN.message_passing\u001b[1;34m(self, iterations)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m sign \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m+1\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     37\u001b[0m     new_features_a_b \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures_b[\u001b[38;5;28mstr\u001b[39m(neighbor)]\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 38\u001b[0m     count_b \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     40\u001b[0m     new_features_a_u \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeatures_b[\u001b[38;5;28mstr\u001b[39m(neighbor)]\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "sbgnn=SBGNN(B,32,32)\n",
    "community=Community(sbgnn,20)\n",
    "\n",
    "train_sbgnn(sbgnn,community)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
